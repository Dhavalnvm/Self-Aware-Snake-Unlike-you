# Self-Aware-Snake (Unlike you)

# ğŸ RL-Snake: Reinforcement Learning Snake Game

Welcome to **RL-Snake**, a machine learning-enhanced version of the classic Snake game, where an AI agent learns to play using Q-learning. Yes, itâ€™s exactly as unnecessary and over-engineered as it sounds.

## ğŸ® Features

* âœ… Q-Learning-based AI agent
* âœ… Obstacle generation for added chaos
* âœ… Optional human mode (for you control freaks)
* âœ… Menu system with keypress navigation (we're fancy now)
* âœ… Custom reward shaping & state representation
* âœ… Training visualization and score plotting
* âœ… Saves and loads Q-table using `pickle` like itâ€™s 2009

## ğŸ§  How It Works

The snake learns by interacting with the environment:

* **State Space**: Considers immediate dangers, food direction, and current movement direction.
* **Actions**: `'straight'`, `'left'`, `'right'`
* **Rewards**:

  * +10 for eating food
  * -10 for hitting walls, self, or obstacles
  * Â±0.1 for moving toward/away from food
* **Q-Table**: Stored in a `defaultdict` mapping states to action-values.

Training uses a simple epsilon-greedy policy with decay, so the snake starts off dumb and slowly becomes less dumb. Like most of us.

## ğŸ–¥ï¸ Requirements

* Python 3.7+
* `pygame`
* `numpy`
* `matplotlib`

Install them like this (unless you enjoy suffering):

```bash
pip install pygame numpy matplotlib
```

## ğŸš€ How to Run

```bash
python rl_snake.py
```

Then choose a mode:

* **T**: Train the AI from scratch
* **P**: Watch the AI slither around and pretend itâ€™s impressive
* **H**: Play the game yourself (so you can lose to your own creation)
* **Q**: Quit. The only mode that respects your time.

## ğŸ“ˆ Training Output

* Progress is visualized during training (optional).
* Scores and moving averages are saved to `training_scores.png`.
* The Q-table is saved to `q_table.pkl` after training.

## ğŸª¦ Known Issues

* The AI still occasionally dies doing something inexplicably stupid. Just like real intelligence.
* Large Q-tables can grow rapidly depending on the state encoding. Use responsibly.
* If you forget to save your Q-table... thatâ€™s on you.

## ğŸ¤·â€â™‚ï¸ Future Work

* Neural network version (DQN) because we love complexity.
* Smarter state representations (vision grid, danger radius).
* Online leaderboard? LOL.

